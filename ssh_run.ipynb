{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200604-11:43:46,785 nipype.utils INFO:\n",
      "\t Running nipype version 1.5.0-rc1 (latest: 1.5.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import warnings\n",
    "import shutil\n",
    "\n",
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "from nipype.interfaces.ants import N4BiasFieldCorrection\n",
    "\n",
    "import pdb\n",
    "from train_model import config\n",
    "from tqdm import tqdm\n",
    "from dev_tools.my_tools import print_red\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image(subject_folder, name):\n",
    "    file_card = os.path.join(subject_folder, \"*\" + name + \".nii.gz\")\n",
    "    try:\n",
    "        return glob.glob(file_card)[0]\n",
    "    except IndexError:\n",
    "        raise RuntimeError(\"Could not find file matching {}\".format(file_card))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_bias(in_file, out_file, image_type=sitk.sitkFloat64):\n",
    "    \"\"\"\n",
    "    Corrects the bias using ANTs N4BiasFieldCorrection. If this fails, will then attempt to correct bias using SimpleITK\n",
    "    :param in_file: input file path\n",
    "    :param out_file: output file path\n",
    "    :return: file path to the bias corrected image\n",
    "    \"\"\"\n",
    "    correct = N4BiasFieldCorrection()\n",
    "    correct.inputs.input_image = in_file\n",
    "    correct.inputs.output_image = out_file\n",
    "    try:\n",
    "        done = correct.run()\n",
    "        return done.outputs.output_image\n",
    "    except IOError:\n",
    "        warnings.warn(RuntimeWarning(\"ANTs N4BIasFieldCorrection could not be found.\"\n",
    "                                     \"Will try using SimpleITK for bias field correction\"\n",
    "                                     \" which will take much longer. To fix this problem, add N4BiasFieldCorrection\"\n",
    "                                     \" to your PATH system variable. (example: EXPORT PATH=${PATH}:/path/to/ants/bin)\"))\n",
    "        input_image = sitk.ReadImage(in_file, image_type)\n",
    "        output_image = sitk.N4BiasFieldCorrection(input_image, input_image > 0)\n",
    "        sitk.WriteImage(output_image, out_file)\n",
    "        return os.path.abspath(out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_image(in_file, out_file, bias_correction=True):\n",
    "    if not os.path.exists(out_file):\n",
    "        if bias_correction:\n",
    "            correct_bias(in_file, out_file)\n",
    "        else:\n",
    "            shutil.copy(in_file, out_file)\n",
    "    return out_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_origin(in_file, in_file2):\n",
    "    image = sitk.ReadImage(in_file)\n",
    "    image2 = sitk.ReadImage(in_file2)\n",
    "    if not image.GetOrigin() == image2.GetOrigin():\n",
    "        image.SetOrigin(image2.GetOrigin())\n",
    "        sitk.WriteImage(image, in_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_brats_folder(in_folder, out_folder, truth_name='seg', no_bias_correction_modalities=None, bias_correct=True):\n",
    "#     pdb.set_trace()\n",
    "    for name in config[\"all_modalities\"]:\n",
    "        try:\n",
    "            image_file = get_image(in_folder, name)\n",
    "        except RuntimeError as error:\n",
    "            if name == 't1ce':\n",
    "                print_red(in_fold)\n",
    "                image_file = get_image(in_folder, 't1Gd')\n",
    "                truth_name = \"GlistrBoost_ManuallyCorrected\"\n",
    "            else:\n",
    "                raise error\n",
    "\n",
    "        out_file = os.path.abspath(os.path.join(out_folder, name + \".nii.gz\"))\n",
    "        \n",
    "        if bias_correct:\n",
    "            perform_bias_correction = no_bias_correction_modalities and name not in no_bias_correction_modalities\n",
    "            normalize_image(image_file, out_file, bias_correction=perform_bias_correction)\n",
    "        else:\n",
    "            if not os.path.exists(out_file):\n",
    "                shutil.copy(image_file, out_file)\n",
    "    \n",
    "    # copy the truth file only for training dataset\n",
    "    if in_folder.split('/')[-2] == 'val':\n",
    "        return\n",
    "    try:\n",
    "        truth_file = get_image(in_folder, truth_name)\n",
    "    except RuntimeError:\n",
    "        truth_file = get_image(in_folder, truth_name.split(\"_\")[0])\n",
    "\n",
    "    out_file = os.path.abspath(os.path.join(out_folder, \"truth.nii.gz\"))\n",
    "    if not os.path.exists(out_file):\n",
    "        shutil.copy(truth_file, out_file)\n",
    "    check_origin(out_file, get_image(in_folder, config[\"all_modalities\"][0]))\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_brats_folder_validation(in_folder, out_folder, no_bias_correction_modalities=None, bias_correct=True):\n",
    "#     pdb.set_trace()\n",
    "    for name in config[\"all_modalities\"]:\n",
    "        try:\n",
    "            image_file = get_image(in_folder, name)\n",
    "        except RuntimeError as error:\n",
    "            if name == 't1ce':\n",
    "                print_red(in_fold)\n",
    "                image_file = get_image(in_folder, 't1Gd')\n",
    "                #truth_name = \"GlistrBoost_ManuallyCorrected\"\n",
    "            else:\n",
    "                raise error\n",
    "\n",
    "        out_file = os.path.abspath(os.path.join(out_folder, name + \".nii.gz\"))\n",
    "        \n",
    "        if bias_correct:\n",
    "            perform_bias_correction = no_bias_correction_modalities and name not in no_bias_correction_modalities\n",
    "            normalize_image(image_file, out_file, bias_correction=perform_bias_correction)\n",
    "        else:\n",
    "            if not os.path.exists(out_file):\n",
    "                shutil.copy(image_file, out_file)\n",
    "\n",
    "    #out_file = os.path.abspath(os.path.join(out_folder, \"truth.nii.gz\"))\n",
    "    #if not os.path.exists(out_file):\n",
    "        #shutil.copy(truth_file, out_file)\n",
    "    check_origin(out_file, get_image(in_folder, config[\"all_modalities\"][0]))\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_brats_data(brats_folder, out_folder, bias_correct=True, overwrite=True, no_bias_correction_modalities=(\"flair\", \"t1ce\", \"t1\", \"t2\")):\n",
    "    #(\"flair\", \"t1ce\", \"t1\", \"t2\")\n",
    "    \"\"\"\n",
    "    Preprocesses the BRATS data and writes it to a given output folder. \n",
    "    :param brats_folder: folder containing the original brats data\n",
    "    :param out_folder: output folder to which the preprocessed data will be written\n",
    "    :param bias_correct: if False, just copy the original images to preprocessed folders.\n",
    "    :param overwrite: set to True in order to redo all the preprocessing\n",
    "    :param no_bias_correction_modalities: performing bias correction could reduce the signal of certain modalities. If\n",
    "    concerned about a reduction in signal for a specific modality, specify by including the given modality in a list\n",
    "    or tuple.\n",
    "    :return:\n",
    "    \"\"\"\n",
    "#     pdb.set_trace()\n",
    "    \n",
    "    for subject_folder in tqdm(glob.glob(os.path.join(brats_folder, \"*\", \"*\"))):\n",
    "#         continue\n",
    "        if os.path.isdir(subject_folder):\n",
    "            subject = os.path.basename(subject_folder)\n",
    "            new_subject_folder = os.path.join(out_folder, os.path.basename(os.path.dirname(subject_folder)),\n",
    "                                              subject)\n",
    "            if not os.path.exists(new_subject_folder) or overwrite:\n",
    "                if not os.path.exists(new_subject_folder):\n",
    "                    os.makedirs(new_subject_folder)\n",
    "                convert_brats_folder(subject_folder, new_subject_folder,\n",
    "                                     no_bias_correction_modalities=no_bias_correction_modalities,bias_correct=bias_correct)\n",
    "        else:\n",
    "            print(subject_folder)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_brats_data_validation(brats_folder, out_folder, bias_correct=True, overwrite=True, no_bias_correction_modalities=(\"flair\", \"t1ce\", \"t1\", \"t2\")):\n",
    "    #(\"flair\", \"t1ce\", \"t1\", \"t2\")\n",
    "    \"\"\"\n",
    "    Preprocesses the BRATS data and writes it to a given output folder. \n",
    "    :param brats_folder: folder containing the original brats data\n",
    "    :param out_folder: output folder to which the preprocessed data will be written\n",
    "    :param bias_correct: if False, just copy the original images to preprocessed folders.\n",
    "    :param overwrite: set to True in order to redo all the preprocessing\n",
    "    :param no_bias_correction_modalities: performing bias correction could reduce the signal of certain modalities. If\n",
    "    concerned about a reduction in signal for a specific modality, specify by including the given modality in a list\n",
    "    or tuple.\n",
    "    :return:\n",
    "    \"\"\"\n",
    "#     pdb.set_trace()\n",
    "    \n",
    "    for subject_folder in tqdm(glob.glob(os.path.join(brats_folder, \"*\", \"*\"))):\n",
    "#         continue\n",
    "        if os.path.isdir(subject_folder):\n",
    "            subject = os.path.basename(subject_folder)\n",
    "            new_subject_folder = os.path.join(out_folder, os.path.basename(os.path.dirname(subject_folder)),\n",
    "                                              subject)\n",
    "            if not os.path.exists(new_subject_folder) or overwrite:\n",
    "                if not os.path.exists(new_subject_folder):\n",
    "                    os.makedirs(new_subject_folder)\n",
    "                convert_brats_folder_validation(subject_folder, new_subject_folder,\n",
    "                                     no_bias_correction_modalities=no_bias_correction_modalities,bias_correct=bias_correct)\n",
    "        else:\n",
    "            print(subject_folder)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nconvert_brats_data('../data/original/','../data/preprocessed/')\\n# validation dataset\\nconvert_brats_data_validation('../data/val_data/','../data/preprocessed_val_data/')\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from preprocess import convert_brats_data\n",
    "# training dataset\n",
    "'''\n",
    "convert_brats_data('../data/original/','../data/preprocessed/')\n",
    "# validation dataset\n",
    "convert_brats_data_validation('../data/val_data/','../data/preprocessed_val_data/')\n",
    "'''\n",
    "# # if you wanna get rid of bias correction, just do this:\n",
    "# convert_brats_data('../data/original/','../data/preprocessed/',bias_correct=False)\n",
    "# convert_brats_data('../data/val_data/','../data/preprocessed_val_data/',bias_correct=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\user\\.conda\\envs\\test\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\user\\.conda\\envs\\test\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\user\\.conda\\envs\\test\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\user\\.conda\\envs\\test\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\user\\.conda\\envs\\test\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\user\\.conda\\envs\\test\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\user\\.conda\\envs\\test\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\user\\.conda\\envs\\test\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\user\\.conda\\envs\\test\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\user\\.conda\\envs\\test\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\user\\.conda\\envs\\test\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From c:\\users\\user\\.conda\\envs\\test\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Loading previous validation split...\n",
      "Number of training steps in each epoch:  2079\n",
      "Number of validation steps in each epoch:  540\n",
      "WARNING:tensorflow:From c:\\users\\user\\.conda\\envs\\test\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\user\\.conda\\envs\\test\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Epoch 1/300\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "from unet3d.data import write_data_to_file, open_data_file\n",
    "from unet3d.generator import get_training_and_validation_generators\n",
    "from unet3d.model import isensee2017_model\n",
    "from unet3d.training import load_old_model, train_model\n",
    "#import pdb\n",
    "import time\n",
    "from dev_tools.my_tools import sec2hms\n",
    "\n",
    "config = dict()\n",
    "config[\"overwrite\"] = False              # To overwrite data.h5.\n",
    "config[\"pool_size\"] = (2, 2, 2)          # pool size for the max pooling operations\n",
    "\n",
    "config[\"image_shape\"] = (240,240,155)  # This determines what shape the images will be cropped/resampled to.\n",
    "config[\"patch_shape\"] = (128, 128, 128) #(128, 128, 128)     # switch to None to train on the whole image\n",
    "config[\"training_patch_start_offset\"] = (4, 4, 4)  # randomly offset the first patch index by up to this offset\n",
    "config[\"validation_patch_overlap\"] = 32                # if > 0, during training, validation patches will be overlapping\n",
    "\n",
    "# config['pred_specific'] = True           # To train with patching strategy specificly for prediction. \n",
    "config['pred_specific'] = False\n",
    "\n",
    "config['center_patch'] = True            # To include the center patch in the patching strategy.\n",
    "\n",
    "config[\"batch_size\"] = 1\n",
    "config[\"validation_batch_size\"] = 1#2\n",
    "config[\"n_epochs\"] = 300\n",
    "config[\"data_file\"] = os.path.abspath(\"../data/data.h5\")\n",
    "# config[\"data_file\"] = os.path.abspath(\"../data/test_trashcan/data.h5\")\n",
    "config[\"model_file\"] = os.path.abspath(\"seg_model.h5\")\n",
    "config['mean_std_file'] = os.path.abspath('../data/mean_std.pkl')\n",
    "config['val_data_file'] = os.path.abspath(\"../data/val_data.h5\")\n",
    "\n",
    "config['val_predict_dir'] = os.path.abspath(\"val_prediction\")\n",
    "config['val_index_list'] = os.path.abspath('../data/val_index_list.pkl')\n",
    "\n",
    "config['num_val_subjects'] = 125\n",
    "# config['num_val_subjects'] = 166  # manually set the number of validation subjects! \n",
    "                                    # You need to refresh config['val_index_list'] once you changed config['num_val_subjects']\n",
    "config['val_to_upload'] = os.path.abspath('saves/val_to_upload')\n",
    "\n",
    "config['training_predict_dir'] = os.path.abspath(\"training_prediction\")\n",
    "config['training_index_list'] = os.path.abspath('../data/training_index_list.pkl')\n",
    "config['num_training_subjects'] = 335  # manually set the number of training subjects (for final uploading)\n",
    "                                         # You need to refresh config['training_index_list'] once you changed \n",
    "                                         # config['num_training_subjects']\n",
    "config['training_to_upload'] = os.path.abspath('saves/training_to_upload')\n",
    "\n",
    "\n",
    "#------------------- 5-fold cross validation -----------------------------------\n",
    "# config[\"training_file\"] = os.path.abspath(\"../data/list_training_ids.pkl\")\n",
    "# config[\"validation_file\"] = os.path.abspath(\"../data/list_validation_ids.pkl\")\n",
    "\n",
    "config[\"training_file\"] = os.path.abspath(\"../data/list_cv1_train.pkl\")\n",
    "config[\"validation_file\"] = os.path.abspath(\"../data/list_cv1_val.pkl\")\n",
    "\n",
    "# config[\"training_file\"] = os.path.abspath(\"../data/list_cv2_train.pkl\")\n",
    "# config[\"validation_file\"] = os.path.abspath(\"../data/list_cv2_val.pkl\")\n",
    "\n",
    "#config[\"training_file\"] = os.path.abspath(\"../data/list_cv3_train.pkl\")\n",
    "#config[\"validation_file\"] = os.path.abspath(\"../data/list_cv3_val.pkl\")\n",
    "\n",
    "# config[\"training_file\"] = os.path.abspath(\"../data/list_cv4_train.pkl\")\n",
    "# config[\"validation_file\"] = os.path.abspath(\"../data/list_cv4_val.pkl\")\n",
    "\n",
    "config['for_final_val'] = True\n",
    "#--------------------------------------------------------------------------------\n",
    "config['logging_file'] = os.path.abspath('training.log')\n",
    "\n",
    "# truth.shape = (240,240,155) with value in [1,2,4], if 4 is on top of others or surrounded by others \n",
    "# config['overlap_label_generator'] = False\n",
    "# config['overlap_label_predict'] = False\n",
    "config['overlap_label_generator'] = True\n",
    "config['overlap_label_predict'] = True\n",
    "\n",
    "\n",
    "config[\"labels\"] = (1, 2, 4)             # the label numbers on the input image\n",
    "config[\"n_labels\"] = len(config[\"labels\"])\n",
    "config[\"all_modalities\"] = [\"t1\", \"t1ce\", \"flair\", \"t2\"]\n",
    "config[\"training_modalities\"] = config[\"all_modalities\"]  # change this if you want to only use some of the modalities\n",
    "config[\"nb_channels\"] = len(config[\"training_modalities\"])\n",
    "config[\"n_base_filters\"] = 16\n",
    "\n",
    "if \"patch_shape\" in config and config[\"patch_shape\"] is not None:\n",
    "    config[\"input_shape\"] = tuple([config[\"nb_channels\"]] + list(config[\"patch_shape\"]))\n",
    "else:\n",
    "    config[\"input_shape\"] = tuple([config[\"nb_channels\"]] + list(config[\"image_shape\"]))\n",
    "\n",
    "config[\"truth_channel\"] = config[\"nb_channels\"]\n",
    "config[\"deconvolution\"] = True           # if False, will use upsampling instead of deconvolution\n",
    "\n",
    "\n",
    "config[\"patience\"] = 10    # learning rate will be reduced after this many epochs if the validation loss is not improving\n",
    "config[\"early_stop\"] = 50  # training will be stopped after this many epochs without the validation loss improving\n",
    "config[\"initial_learning_rate\"] = 5e-4\n",
    "config[\"learning_rate_drop\"] = 0.5  # factor by which the learning rate will be reduced\n",
    "config[\"validation_split\"] = 1.0#0.8    # portion of the data that will be used for training\n",
    "\n",
    "# config[\"flip\"] = False              # augments the data by randomly flipping an axis during\n",
    "config[\"flip\"] = True\n",
    "config[\"permute\"] = True  # data shape must be a cube. Augments the data by permuting in various directions\n",
    "# config[\"distort\"] = None  # switch to None if you want no distortion\n",
    "config[\"distort\"] = 0.25\n",
    "config[\"augment\"] = config[\"flip\"] or config[\"distort\"]\n",
    "\n",
    "config[\"skip_blank\"] = True                           # if True, then patches without any target will be skipped\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def fetch_training_data_files(return_subject_ids=False):\n",
    "    training_data_files = list()\n",
    "    subject_ids = list()\n",
    "    for subject_dir in glob.glob(os.path.join(\"../data\", \"preprocessed\", \"*\", \"*\")):\n",
    "        subject_ids.append(os.path.basename(subject_dir))\n",
    "        subject_files = list()\n",
    "        for modality in config[\"training_modalities\"] + [\"truth\"]:\n",
    "            subject_files.append(os.path.join(subject_dir, modality + \".nii.gz\"))\n",
    "        training_data_files.append(tuple(subject_files))\n",
    "    if return_subject_ids:\n",
    "        return training_data_files, subject_ids\n",
    "    else:\n",
    "        return training_data_files\n",
    "\n",
    "\n",
    "def main(overwrite=False):\n",
    "    # convert input images into an hdf5 file\n",
    "    #pdb.set_trace()\n",
    "    if overwrite or not os.path.exists(config[\"data_file\"]):\n",
    "        training_files, subject_ids = fetch_training_data_files(return_subject_ids=True)\n",
    "\n",
    "        write_data_to_file(training_files, \n",
    "                            config[\"data_file\"], \n",
    "                            image_shape=config[\"image_shape\"], \n",
    "                            modality_names = config['all_modalities'],\n",
    "                            subject_ids=subject_ids,\n",
    "                           mean_std_file = config['mean_std_file'])\n",
    "#     return\n",
    "    data_file_opened = open_data_file(config[\"data_file\"])\n",
    "\n",
    "    if not overwrite and os.path.exists(config[\"model_file\"]):\n",
    "        model = load_old_model(config[\"model_file\"])\n",
    "    else:\n",
    "        # instantiate new model\n",
    "        model = isensee2017_model(input_shape=config[\"input_shape\"], n_labels=config[\"n_labels\"],\n",
    "                                  initial_learning_rate=config[\"initial_learning_rate\"],\n",
    "                                  n_base_filters=config[\"n_base_filters\"])\n",
    "\n",
    "    # get training and testing generators\n",
    "#     pdb.set_trace()\n",
    "    train_generator, validation_generator, n_train_steps, n_validation_steps = get_training_and_validation_generators(\n",
    "        data_file_opened,\n",
    "        batch_size=config[\"batch_size\"],\n",
    "        data_split=config[\"validation_split\"],\n",
    "        overwrite=overwrite,\n",
    "        validation_keys_file=config[\"validation_file\"],\n",
    "        training_keys_file=config[\"training_file\"],\n",
    "        n_labels=config[\"n_labels\"],\n",
    "        labels=config[\"labels\"],\n",
    "        patch_shape=config[\"patch_shape\"],\n",
    "        validation_batch_size=config[\"validation_batch_size\"],\n",
    "        validation_patch_overlap=config[\"validation_patch_overlap\"],\n",
    "        training_patch_start_offset=config[\"training_patch_start_offset\"],\n",
    "        permute=config[\"permute\"],\n",
    "        augment=config[\"augment\"],\n",
    "        skip_blank=config[\"skip_blank\"],\n",
    "        augment_flip=config[\"flip\"],\n",
    "        augment_distortion_factor=config[\"distort\"],\n",
    "        pred_specific=config['pred_specific'],\n",
    "        overlap_label=config['overlap_label_generator'],\n",
    "        for_final_val=config['for_final_val'])\n",
    "\n",
    "    # run training\n",
    "#     pdb.set_trace()\n",
    "    time_0 = time.time()\n",
    "    train_model(model=model,\n",
    "                model_file=config[\"model_file\"],\n",
    "                training_generator=train_generator,\n",
    "                validation_generator=validation_generator,\n",
    "                steps_per_epoch=n_train_steps,\n",
    "                validation_steps=n_validation_steps,\n",
    "                initial_learning_rate=config[\"initial_learning_rate\"],\n",
    "                learning_rate_drop=config[\"learning_rate_drop\"],\n",
    "                learning_rate_patience=config[\"patience\"],\n",
    "                early_stopping_patience=config[\"early_stop\"],\n",
    "                n_epochs=config[\"n_epochs\"],\n",
    "                logging_file = config['logging_file'])\n",
    "    print('Training time:', sec2hms(time.time() - time_0))\n",
    "    data_file_opened.close()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(overwrite=config[\"overwrite\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
